{
  "best_global_step": 300,
  "best_metric": 0.10820937156677246,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 372,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08064516129032258,
      "grad_norm": 3.7345831394195557,
      "learning_rate": 9e-07,
      "loss": 1.453,
      "step": 10
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 3.9696903228759766,
      "learning_rate": 1.9e-06,
      "loss": 1.4175,
      "step": 20
    },
    {
      "epoch": 0.24193548387096775,
      "grad_norm": 3.5031144618988037,
      "learning_rate": 2.9e-06,
      "loss": 1.3638,
      "step": 30
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 3.3151750564575195,
      "learning_rate": 3.9e-06,
      "loss": 1.2593,
      "step": 40
    },
    {
      "epoch": 0.4032258064516129,
      "grad_norm": 3.210019826889038,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 1.1613,
      "step": 50
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 4.9225172996521,
      "learning_rate": 5.9e-06,
      "loss": 1.0312,
      "step": 60
    },
    {
      "epoch": 0.5645161290322581,
      "grad_norm": 2.1774890422821045,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.9394,
      "step": 70
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 2.739738941192627,
      "learning_rate": 7.9e-06,
      "loss": 0.8313,
      "step": 80
    },
    {
      "epoch": 0.7258064516129032,
      "grad_norm": 2.072486639022827,
      "learning_rate": 8.9e-06,
      "loss": 0.7587,
      "step": 90
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 2.837878465652466,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.6936,
      "step": 100
    },
    {
      "epoch": 0.8064516129032258,
      "eval_loss": 0.6800221800804138,
      "eval_runtime": 47.3709,
      "eval_samples_per_second": 10.471,
      "eval_steps_per_second": 0.654,
      "step": 100
    },
    {
      "epoch": 0.8870967741935484,
      "grad_norm": 2.71453595161438,
      "learning_rate": 1.09e-05,
      "loss": 0.5808,
      "step": 110
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 2.213841676712036,
      "learning_rate": 1.19e-05,
      "loss": 0.4091,
      "step": 120
    },
    {
      "epoch": 1.0483870967741935,
      "grad_norm": 1.734025001525879,
      "learning_rate": 1.29e-05,
      "loss": 0.3562,
      "step": 130
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 1.3534022569656372,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.2348,
      "step": 140
    },
    {
      "epoch": 1.2096774193548387,
      "grad_norm": 1.5250533819198608,
      "learning_rate": 1.49e-05,
      "loss": 0.2435,
      "step": 150
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 2.20452618598938,
      "learning_rate": 1.59e-05,
      "loss": 0.297,
      "step": 160
    },
    {
      "epoch": 1.370967741935484,
      "grad_norm": 0.9141080975532532,
      "learning_rate": 1.69e-05,
      "loss": 0.1477,
      "step": 170
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 1.4871512651443481,
      "learning_rate": 1.79e-05,
      "loss": 0.1151,
      "step": 180
    },
    {
      "epoch": 1.532258064516129,
      "grad_norm": 2.1915886402130127,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.1914,
      "step": 190
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 11.646939277648926,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.1682,
      "step": 200
    },
    {
      "epoch": 1.6129032258064515,
      "eval_loss": 0.2167031615972519,
      "eval_runtime": 57.1513,
      "eval_samples_per_second": 8.679,
      "eval_steps_per_second": 0.542,
      "step": 200
    },
    {
      "epoch": 1.6935483870967742,
      "grad_norm": 0.5958195924758911,
      "learning_rate": 2.09e-05,
      "loss": 0.1427,
      "step": 210
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 1.6189712285995483,
      "learning_rate": 2.19e-05,
      "loss": 0.2366,
      "step": 220
    },
    {
      "epoch": 1.8548387096774195,
      "grad_norm": 3.0660552978515625,
      "learning_rate": 2.29e-05,
      "loss": 0.1227,
      "step": 230
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 3.3334343433380127,
      "learning_rate": 2.39e-05,
      "loss": 0.1857,
      "step": 240
    },
    {
      "epoch": 2.0161290322580645,
      "grad_norm": 0.36732691526412964,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.1033,
      "step": 250
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 40.587562561035156,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.1329,
      "step": 260
    },
    {
      "epoch": 2.1774193548387095,
      "grad_norm": 0.2028077393770218,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0466,
      "step": 270
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.15743541717529297,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0126,
      "step": 280
    },
    {
      "epoch": 2.338709677419355,
      "grad_norm": 0.13536718487739563,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0529,
      "step": 290
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 1.8462581634521484,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0788,
      "step": 300
    },
    {
      "epoch": 2.4193548387096775,
      "eval_loss": 0.10820937156677246,
      "eval_runtime": 79.6384,
      "eval_samples_per_second": 6.228,
      "eval_steps_per_second": 0.389,
      "step": 300
    },
    {
      "epoch": 2.5,
      "grad_norm": 10.681151390075684,
      "learning_rate": 3.09e-05,
      "loss": 0.1065,
      "step": 310
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.10904989391565323,
      "learning_rate": 3.19e-05,
      "loss": 0.0324,
      "step": 320
    },
    {
      "epoch": 2.661290322580645,
      "grad_norm": 9.591778755187988,
      "learning_rate": 3.29e-05,
      "loss": 0.0935,
      "step": 330
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.14958713948726654,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0383,
      "step": 340
    },
    {
      "epoch": 2.8225806451612905,
      "grad_norm": 0.9983152747154236,
      "learning_rate": 3.49e-05,
      "loss": 0.0673,
      "step": 350
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.1707424819469452,
      "learning_rate": 3.59e-05,
      "loss": 0.0359,
      "step": 360
    },
    {
      "epoch": 2.9838709677419355,
      "grad_norm": 0.07478397339582443,
      "learning_rate": 3.69e-05,
      "loss": 0.0072,
      "step": 370
    }
  ],
  "logging_steps": 10,
  "max_steps": 372,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 266417999156736.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
